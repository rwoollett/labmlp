    //    MatrixXd nHiddenActivationWithBias(m_nData, m_nHidden + 1);
//    MatrixXd outputs(m_nData, m_nOut);
    // nHiddenActivationWithBias.block(0, 0, m_nData, m_nHidden) << inputsWithBiasEntry * m_weights1;
    // nHiddenActivationWithBias.col(m_nHidden).tail(m_nData) << biasInput;
    // the following equationa are the fwd process of the mlp train
    // TODO: make the fwd process just do the fwd step and a new bckpropagate function in the train
    // for (int nData = 0; nData < m_nData; nData++)
    // {
    //   for (int n = 0; n < m_nHidden; n++)
    //   {
    //     double resH = (1.0 / (1.0 + std::exp(-1.0 * m_beta * nHiddenActivationWithBias(nData, n))));
    //     nHiddenActivationWithBias(nData, n) = resH; //(1.0 / (1.0 + std::exp(-1.0 * m_beta * nHiddenActivationWithBias(nData, n))));
    //   }
    // }

    
    // outputs = nHiddenActivationWithBias * m_weights2;

    // for (int nData = 0; nData < m_nData; nData++)
    // {
    //   for (int o = 0; o < m_nOut; o++)
    //   {
    //     double resO = 1.0 / (1.0 + std::exp(-1.0 * m_beta * outputs(nData, o)));
    //     outputs(nData, o) = resO;
    //   }
    // }
    // end of fwd process - outputs are the activated results
